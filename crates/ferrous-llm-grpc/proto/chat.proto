syntax = "proto3";

package ferrous_llm.chat;

import "google/protobuf/timestamp.proto";
import "google/protobuf/struct.proto";

// Chat service definition
service ProtoChatService {
    // Send a chat request and receive a response
    rpc Chat(ProtoChatRequest) returns (ProtoChatResponse);

    // Send a chat request and receive a streaming response
    rpc ChatStream(ProtoChatRequest) returns (stream ProtoChatStreamResponse);
}

// A chat request containing messages and parameters
message ProtoChatRequest {
    // The conversation messages
    repeated ProtoMessage messages = 1;

    // Request parameters
    ProtoParameters parameters = 2;

    // Additional metadata
    ProtoMetadata metadata = 3;
}

// A chat response
message ProtoChatResponse {
    // The response content
    string content = 1;

    // Usage statistics
    optional ProtoUsage usage = 2;

    // Reason why generation finished
    optional ProtoFinishReason finish_reason = 3;

    // Response metadata
    ProtoMetadata metadata = 4;

    // Tool calls if any were made
    repeated ProtoToolCall tool_calls = 5;
}

// A streaming chat response chunk
message ProtoChatStreamResponse {
    // Incremental content
    string content = 1;

    // Whether this is the final chunk
    bool is_final = 2;

    // Usage statistics (only in final chunk)
    optional ProtoUsage usage = 3;

    // Finish reason (only in final chunk)
    optional ProtoFinishReason finish_reason = 4;

    // Response metadata
    ProtoMetadata metadata = 5;

    // Tool calls if any were made
    repeated ProtoToolCall tool_calls = 6;
}

// A message in a conversation
message ProtoMessage {
    // The role of the message sender
    ProtoRole role = 1;

    // The content of the message
    ProtoMessageContent content = 2;
}

// The role of a message sender
enum ProtoRole {
    ROLE_UNSPECIFIED = 0;
    ROLE_USER = 1;
    ROLE_ASSISTANT = 2;
    ROLE_SYSTEM = 3;
    ROLE_TOOL = 4;
}

// Content of a message
message ProtoMessageContent {
    oneof proto_content_type {
        // Simple text content
        string text = 1;

        // Multimodal content with text and other media
        ProtoMultimodalContent multimodal = 2;

        // Tool-related content
        ProtoToolContent tool = 3;
    }
}

// Multimodal content with multiple parts
message ProtoMultimodalContent {
    repeated ProtoContentPart parts = 1;
}

// Tool-related message content
message ProtoToolContent {
    // Tool calls made by the assistant
    repeated ProtoToolCall tool_calls = 1;

    // Tool call ID if this is a tool response
    optional string tool_call_id = 2;

    // Optional text content alongside tool data
    optional string text = 3;
}

// A part of multimodal message content
message ProtoContentPart {
    oneof proto_part_type {
        // Text content
        ProtoTextPart text = 1;

        // Image content
        ProtoImagePart image = 2;

        // Audio content
        ProtoAudioPart audio = 3;
    }
}

// Text content part
message ProtoTextPart {
    string text = 1;
}

// Image content part
message ProtoImagePart {
    // Image data or URL
    ProtoImageSource image_source = 1;

    // Optional detail level for image processing
    optional string detail = 2;
}

// Audio content part
message ProtoAudioPart {
    // Audio data or URL
    string audio_url = 1;

    // Audio format (mp3, wav, etc.)
    optional string format = 2;
}

// Image source
message ProtoImageSource {
    oneof proto_source_type {
        // URL (or base64 data) or bytes
        string url = 1;
        bytes data = 2;
    }
}

// A tool/function call made by the AI
message ProtoToolCall {
    // Unique identifier for this tool call
    string id = 1;

    // The type of tool call (usually "function")
    string call_type = 2;

    // The function being called
    ProtoFunctionCall function = 3;
}

// A function call within a tool call
message ProtoFunctionCall {
    // Name of the function to call
    string name = 1;

    // Arguments to pass to the function (JSON string)
    string arguments = 2;
}

// Common parameters used across providers
message ProtoParameters {
    // Controls randomness in the response (0.0 to 2.0)
    optional float temperature = 1;

    // Maximum number of tokens to generate
    optional uint32 max_tokens = 2;

    // Nucleus sampling parameter (0.0 to 1.0)
    optional float top_p = 3;

    // Alternative to temperature, called Top-k sampling
    optional uint32 top_k = 4;

    // Sequences where the API will stop generating further tokens
    repeated string stop_sequences = 5;

    // Number between -2.0 and 2.0. Positive values penalize new tokens based on their existing frequency
    optional float frequency_penalty = 6;

    // Number between -2.0 and 2.0. Positive values penalize new tokens based on whether they appear in the text so far
    optional float presence_penalty = 7;
}

// Metadata for requests and responses
message ProtoMetadata {
    // Provider-specific extensions
    google.protobuf.Struct extensions = 1;

    // Optional request ID for tracking
    optional string request_id = 2;

    // Optional user ID for tracking
    optional string user_id = 3;

    // Timestamp when the request was created
    google.protobuf.Timestamp created_at = 4;
}

// Usage statistics for a request
message ProtoUsage {
    // Number of tokens in the prompt
    uint32 prompt_tokens = 1;

    // Number of tokens in the completion
    uint32 completion_tokens = 2;

    // Total number of tokens used
    uint32 total_tokens = 3;
}

// Reason why the model stopped generating
enum ProtoFinishReason {
    FINISH_REASON_UNSPECIFIED = 0;
    FINISH_REASON_STOP = 1;
    FINISH_REASON_LENGTH = 2;
    FINISH_REASON_STOP_SEQUENCE = 3;
    FINISH_REASON_TOOL_CALLS = 4;
    FINISH_REASON_CONTENT_FILTER = 5;
    FINISH_REASON_ERROR = 6;
}
