[package]
name = "ferrous-llm-examples"
version = "0.0.0"
edition = "2024"

[[example]]
name = "demo_openai_chat"
path = "openai_chat.rs"

[[example]]
name = "demo_openai_chat_streaming"
path = "openai_chat_streaming.rs"

[[example]]
name = "demo_ollama_chat"
path = "ollama_chat.rs"

[[example]]
name = "demo_ollama_chat_streaming"
path = "ollama_chat_streaming.rs"

[[example]]
name = "demo_anthropic_chat"
path = "anthropic_chat.rs"

[[example]]
name = "demo_anthropic_chat_streaming"
path = "anthropic_chat_streaming.rs"

[[example]]
name = "demo_openai_image_description"
path = "openai_image_description.rs"

[dependencies]
ferrous-llm = { path = "..", features = ["openai", "ollama", "anthropic"] }
tokio = { workspace = true, features = ["full"] }
tracing-subscriber = "0.3"
futures = "0.3"
chrono = { workspace = true, features = ["serde"] }
dotenv = "0.15"
tracing = "0.1"
base64 = "0.22"
